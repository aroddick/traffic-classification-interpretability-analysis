{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhxnG97S3QA9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO\n",
        "#Try type of traffic for all label categories and document results - Done\n",
        "#Try for full dataset \n",
        "# country of origin dataset training -Done\n",
        "#Try NAM's\n",
        "#Try nprintML on the same sample data and document results"
      ],
      "metadata": {
        "id": "aMeBDSwIoeIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qnWH8kPTsH3"
      },
      "outputs": [],
      "source": [
        "!pip install interpret\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C9Gx7qN3Zut"
      },
      "outputs": [],
      "source": [
        "import interpret\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oiHz8pA4ecO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNeFLtTd3awJ"
      },
      "outputs": [],
      "source": [
        "#metadata = pd.read_csv(\"/content/drive/MyDrive/Data/type_of_traffic/metadata.csv\")\n",
        "#metadata = pd.read_csv(\"/content/drive/MyDrive/Data/country_of_origin/metadata.csv\")\n",
        "metadata = pd.read_csv(\"/content/drive/MyDrive/Data/active_device_case/metadata.csv\")\n",
        "print(\"Number of samples : \", len(metadata))\n",
        "print(\"Number of target classes : \", len(set(metadata.iloc[:, 1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wtm6qHC77WnL"
      },
      "outputs": [],
      "source": [
        "metadata.sample()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1U /content/drive/MyDrive/Data/country_of_origin/  | wc -l"
      ],
      "metadata": {
        "id": "7KCqjdRzfKkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples,features,labels = [],[],[]\n",
        "flag = True\n",
        "count = 1\n",
        "#for _, row in metadata.head(n=100).iterrows():\n",
        "for _, row in metadata.sample(n=5000).iterrows():\n",
        "#for _, row in metadata.iterrows():\n",
        "    #fname = \"/content/drive/MyDrive/Data/type_of_traffic/\" + row[0].split(\".\")[0] + \".npt\"\n",
        "    #fname = \"/content/drive/MyDrive/Data/country_of_origin/\" + row[0].split(\".\")[0] + \".npt\"\n",
        "    fname = \"/content/drive/MyDrive/Data/active_device_case/\" + row[0].split(\".\")[0] + \".npt\"\n",
        "    file_info = pd.read_csv(fname)\n",
        "    #print(fname)\n",
        "    print(\"completed %:\" ,int(count))\n",
        "    #print(int(count))\n",
        "    #print(int(count/len(metadata))*100)\n",
        "    if flag:\n",
        "        feature_list = file_info.columns.values.tolist()\n",
        "        #25 cause number of packets in each sample are 25 : Country of Origin\n",
        "        #21 cause number of packets in each sample are 21 : Active Device\n",
        "        for i in range(1):\n",
        "          features.extend([str(i) + \"_\" + feature for feature in feature_list])\n",
        "        \n",
        "        flag = False\n",
        "    curr_sample = []\n",
        "    packet_count = 0\n",
        "    for _, file_row in file_info.sample(1).iterrows(): # taking only 1 packet\n",
        "        curr_sample.extend(file_row)\n",
        "        packet_count = packet_count + 1\n",
        "\n",
        "    # for i in range(21-packet_count):\n",
        "    #   curr_sample.extend([-1]*len(feature_list))\n",
        "    samples.append(curr_sample)\n",
        "    labels.append(row[1].split(\"-\")[0])\n",
        "    count = count +1"
      ],
      "metadata": {
        "id": "oRCwI5LiwFf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YYMWfRESldNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For type of traffic \n",
        "\n",
        "# df_labels = pd.DataFrame(labels, columns=['label'])\n",
        "# #df_label['label'] = df_labels.label.str.split('-').str[0]\n",
        "# df_label = df_labels.label.str.split('-').str[0]\n",
        "# df_label = pd.DataFrame(df_label, columns=['label'])\n",
        "# #choose type of label : simple,medium,hard label - 0,1,2 index respectively\n",
        "# df_label = df_label.label.str.split('_').str[2]\n",
        "# df_label = pd.DataFrame(df_label, columns=['label'])\n",
        "# df_label.head()\n",
        "# print(df_label['label'].unique())\n",
        "\n",
        "\n",
        "# For Country of Origin\n",
        "\n",
        "# df_labels = pd.DataFrame(labels, columns=['label'])\n",
        "# #df_label['label'] = df_labels.label.str.split('-').str[0]\n",
        "# df_label = df_labels.label.str.split('-').str[0]\n",
        "# df_label = pd.DataFrame(df_label, columns=['label'])\n",
        "# #choose type of label : simple,medium,hard label - 0,1,2 index respectively\n",
        "# df_label = df_label.label.str.split('_').str[2]\n",
        "# df_label = pd.DataFrame(df_label, columns=['label'])\n",
        "# df_label.head()\n",
        "# print(df_label['label'].unique())"
      ],
      "metadata": {
        "id": "YFXhwSeeZNWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels = pd.DataFrame(labels, columns=['label'])\n",
        "#df_labels['label'] = df_labels.label.str.split('-').str[0]\n",
        "print(\"Number of Samples : \", len(samples))\n",
        "print(\"Number of features per sample : \", len(samples[0]), len(features))\n",
        "print(\"Number of labels are \", df_labels['label'].nunique())\n",
        "print(\"Unique of labels are \", df_labels['label'].unique())"
      ],
      "metadata": {
        "id": "hF4g4-FwjdSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_samples = pd.DataFrame(samples,columns=features)"
      ],
      "metadata": {
        "id": "Ciwm6YoVNsW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvs7ZPTF6Q8h"
      },
      "outputs": [],
      "source": [
        "#select only 1st packet\n",
        "## country of origin\n",
        "#df_sample = df_samples.iloc[:,:1425*25]\n",
        "\n",
        "## type of traffic\n",
        "#for i in range(len(samples)):\n",
        "#  df_samples.loc[i] = samples[i][:1105] # Cause different rows seem to have diffferent packet lengths\n",
        "\n",
        "## active device\n",
        "df_sample = df_samples\n",
        "#df_samples = pd.DataFrame(samples, columns=features)\n",
        "df_labels = pd.DataFrame(labels, columns=['label'])\n",
        "df_data = df_sample.join(df_labels,how='outer')\n",
        "\n",
        "print(\"Number of Samples : \", len(samples))\n",
        "print(\"Number of features per sample : \", len(samples[0]), len(features))\n",
        "print(\"Number of labels are \", df_labels['label'].nunique())\n",
        "print(\"Unique of labels are \", df_labels['label'].unique())\n",
        "\n",
        "df_data.fillna(-1)\n",
        "df_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_data['label'] = df_data.label.str.split('-').str[0]"
      ],
      "metadata": {
        "id": "3UBZrD8-k6Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of labels are \", df_data['label'].nunique())\n",
        "print(\"Unique of labels are \", df_data['label'].unique())\n",
        "#df_data.head()"
      ],
      "metadata": {
        "id": "U6B04hmBlmBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#country of origin\n",
        "#df_data['label'] = df_data['label'].map({'china':1,'india':0,'us':2})\n",
        "\n",
        "#active device\n",
        "df_data['label'] = df_data['label'].map({'ubiquoss':0,'axis':1,'mikrotik':2,'cisco':3,'avtech' :4, 'zte':5, 'roku' :6,'lancom' :7,'h3c' :8, 'huawei':9, 'juniper':10, 'chromecast' :11, 'adtran':12, 'nec':13, 'dell':14})\n",
        "\n",
        "# type of traffic\n",
        "#df_data['label'] = df_data['label'].map({'p2p':1,'audio':0})\n",
        "\n",
        "df_data.fillna(-1)\n",
        "df=df_data.isnull().any()\n",
        "df1 = pd.DataFrame(data=df.index, columns=['feature'])\n",
        "df2 = pd.DataFrame(data=df.values, columns=['bool'])\n",
        "df_any = pd.merge(df1, df2, left_index=True, right_index=True)\n",
        "#df_any.head()\n",
        "\n",
        "#check any nulls\n",
        "df_any['bool'].sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "thM7rNSMyx4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = df_data.drop(columns=['0_src_ip','label'],axis=1)\n",
        "#df_features = df_data.drop(columns=['0_src_ip','1_src_ip','2_src_ip','3_src_ip','4_src_ip','label'],axis=1)\n",
        "#df_features = df_data.drop(columns=['0_src_ip','1_src_ip','2_src_ip','3_src_ip','4_src_ip','5_src_ip','6_src_ip','7_src_ip','8_src_ip','9_src_ip','label'],axis=1)\n",
        "#df_features = df_data.drop(columns=['0_src_ip',\n",
        "#  '1_src_ip',\n",
        "#  '2_src_ip',\n",
        "#  '3_src_ip',\n",
        "#  '4_src_ip',\n",
        "#  '5_src_ip',\n",
        "#  '6_src_ip',\n",
        "#  '7_src_ip',\n",
        "#  '8_src_ip',\n",
        "#  '9_src_ip',\n",
        "#  '10_src_ip',\n",
        "#  '11_src_ip',\n",
        "#  '12_src_ip',\n",
        "#  '13_src_ip',\n",
        "#  '14_src_ip',\n",
        "#  '15_src_ip',\n",
        "#  '16_src_ip',\n",
        "#  '17_src_ip',\n",
        "#  '18_src_ip',\n",
        "#  '19_src_ip',\n",
        "#  '20_src_ip','label'],axis=1)\n",
        "#Check for column dtypes\n",
        "[ col  for col, dt in df_data.dtypes.items() if dt == 'string']\n",
        "df_features.dtypes"
      ],
      "metadata": {
        "id": "gBTG0_Gj0rSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "twMY4Sl3iLgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from interpret import show\n",
        "from interpret.glassbox import LogisticRegression, ClassificationTree, ExplainableBoostingClassifier\n",
        "from interpret.perf import ROC\n",
        "from sklearn.metrics import classification_report\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import f1_score,balanced_accuracy_score,roc_auc_score\n",
        "\n",
        "seed = 1\n",
        "#X_train, X_test, y_train, y_test = train_test_split(samples, labels, random_state=seed)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df_features, df_data['label'], random_state=seed)"
      ],
      "metadata": {
        "id": "jd8MX0vs0WoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "y_predict = model.predict(X_test)\n",
        "print(classification_report(y_predict, Y_test))\n",
        "#for comparision with nprintML \n",
        "print(f1_score(Y_test, y_predict, average='macro'))\n",
        "print(balanced_accuracy_score(Y_test, y_predict))"
      ],
      "metadata": {
        "id": "9cHkLOSCwEJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
        "model.fit(X_train, Y_train)\n",
        "y_predict = model.predict(X_test)\n",
        "print(classification_report(y_predict, Y_test))\n",
        "#for comparision with nprintML \n",
        "print(f1_score(Y_test, y_predict, average='macro'))\n",
        "print(balanced_accuracy_score(Y_test, y_predict))"
      ],
      "metadata": {
        "id": "Un4zdxH722FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebm = ExplainableBoostingClassifier(random_state=seed, n_jobs=8, max_rounds=100, max_bins=64, max_interaction_bins=32, binning='quantile', mains='all', outer_bags=8, inner_bags=0, learning_rate=0.1, validation_size=0.15, early_stopping_rounds=5, early_stopping_tolerance=0.1)\n",
        "ebm.fit(X_train, Y_train)\n",
        "\n",
        "y_predict = ebm.predict(X_test)\n",
        "print(classification_report(y_predict, Y_test))\n",
        "\n",
        "#for comparision with nprintML \n",
        "print(f1_score(Y_test, y_predict, average='macro'))\n",
        "print(balanced_accuracy_score(Y_test, y_predict))\n",
        "#ebm_global = ebm.explain_global(name=\"EBM\")\n",
        "#show(ebm_global)"
      ],
      "metadata": {
        "id": "HvN4mD7Y3GgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from interpret.glassbox import LogisticRegression, ClassificationTree\n",
        "\n",
        "lr = LogisticRegression(random_state=seed, penalty='l1', solver='liblinear')\n",
        "lr.fit(X_train, Y_train)\n",
        "\n",
        "y_predict = lr.predict(X_test)\n",
        "print(classification_report(y_predict, Y_test))\n",
        "\n",
        "#for comparision with nprintML \n",
        "print(f1_score(Y_test, y_predict, average='macro'))\n",
        "print(balanced_accuracy_score(Y_test, y_predict))"
      ],
      "metadata": {
        "id": "8NmMoAyzeJqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = ClassificationTree()\n",
        "tree.fit(X_train, Y_train)\n",
        "\n",
        "y_predict = tree.predict(X_test)\n",
        "print(classification_report(y_predict, Y_test))\n",
        "\n",
        "#for comparision with nprintML \n",
        "print(f1_score(Y_test, y_predict, average='macro'))\n",
        "print(balanced_accuracy_score(Y_test, y_predict))"
      ],
      "metadata": {
        "id": "a9zrmvofen50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_global = lr.explain_global(name='Logistic Regression')\n",
        "show(lr_global)"
      ],
      "metadata": {
        "id": "kjKtQIlohN3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_global = tree.explain_global(name='Classification Tree')\n",
        "show(tree_global)"
      ],
      "metadata": {
        "id": "1PQI0Tv-l0TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebm_global = ebm.explain_global(name=\"EBM\")\n",
        "show(ebm_global)"
      ],
      "metadata": {
        "id": "lQ24mYVkOEf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebm_local = ebm.explain_local(X_test[:5], Y_test[:5], name='EBM')\n",
        "show(ebm_local)"
      ],
      "metadata": {
        "id": "BjB12LaLTujZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "blackbox_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
        "blackbox_model.fit(X_train, Y_train)\n",
        "y_predict = blackbox_model.predict(X_test)\n",
        "print(classification_report(y_predict, Y_test))\n",
        "#for comparision with nprintML \n",
        "print(f1_score(Y_test, y_predict, average='macro'))\n",
        "print(balanced_accuracy_score(Y_test, y_predict))"
      ],
      "metadata": {
        "id": "DjMd6AS-I-iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "# explainer = shap.Explainer(blackbox_model)\n",
        "# shap_values = explainer(X_test)\n",
        "\n",
        "explainer = shap.TreeExplainer(blackbox_model)\n",
        "shap_values = explainer.shap_values(X_test)"
      ],
      "metadata": {
        "id": "PFoi9_1JJMvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = 5\n",
        "shap.waterfall_plot(shap.Explanation(values=shap_values[7][row], \n",
        "                                              base_values=explainer.expected_value[7], data=X_test.iloc[row],  \n",
        "                                         feature_names=X_test.columns.tolist()))"
      ],
      "metadata": {
        "id": "Go89t0W2JkI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['ubiquoss','axis','mikrotik','cisco','avtech', 'zte', 'roku','lancom','h3c', 'huawei', 'juniper', 'chromecast', 'adtran', 'nec', 'dell']\n",
        "shap.summary_plot(shap_values, X_test.values, plot_type=\"bar\", class_names= class_names, feature_names = X_test.columns)\n",
        "\n",
        "#Single Class importances\n",
        "#shap.summary_plot(shap_values[1], X_test.values, feature_names = X_test.columns)"
      ],
      "metadata": {
        "id": "3GA4rkIbJQZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize Classifier\n",
        "# lr = LogisticRegression(random_state=seed) #, n_jobs=8, max_rounds=100, max_bins=64, max_interaction_bins=32, binning='quantile', mains='all', outer_bags=8, inner_bags=0, learning_rate=0.01, validation_size=0.15, early_stopping_rounds=5, early_stopping_tolerance=0.001)\n",
        "# lr.fit(X_train, Y_train)\n",
        "\n",
        "# y_predict = lr.predict(X_test)\n",
        "\n",
        "# lr_perf = ROC(lr.predict_proba).explain_perf(X_test, Y_test, name='Logistic Regression')\n",
        "# print(classification_report(y_predict, Y_test))\n",
        "# show(lr_perf)\n",
        "\n",
        "# lr_global = lr.explain_global(name=\"LR\")\n",
        "# show(lr_global)"
      ],
      "metadata": {
        "id": "pJLtWTba26jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EVssNENhI-mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ebm_perf = ROC(ebm.predict_proba).explain_perf(X_test, Y_test, name='EBM')\n",
        "# show(ebm_perf)"
      ],
      "metadata": {
        "id": "0bxSnAP0ZQtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "07liQjGbZjto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from interpret import show\n",
        "# from interpret.glassbox import LogisticRegression, ClassificationTree, ExplainableBoostingClassifier\n",
        "# from interpret.perf import ROC\n",
        "\n",
        "# seed = 1\n",
        "# #X_train, X_test, y_train, y_test = train_test_split(samples, labels, random_state=seed)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df_data.loc[:, df_data.columns != 'label'], df_data['label'], random_state=seed)\n",
        "\n",
        "# # Initialize Classifier\n",
        "# ebm = ExplainableBoostingClassifier(random_state=seed, n_jobs=8, max_rounds=100, max_bins=64, max_interaction_bins=32, binning='quantile', mains='all', outer_bags=8, inner_bags=0, learning_rate=0.01, validation_size=0.15, early_stopping_rounds=5, early_stopping_tolerance=0.001)\n",
        "# ebm.fit(X_train, y_train)\n",
        "\n",
        "# ebm_global = ebm.explain_global(name=\"EBM\")\n",
        "# show(ebm_global)"
      ],
      "metadata": {
        "id": "wo75OlLJ4hUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APP8mNJcr5ga"
      },
      "outputs": [],
      "source": [
        "## To get data from drive into pandas\n",
        "# 1. First extract pcapng files from zip after downloading from drive link\n",
        "# 2. Convert pcapng to pcap format with following command \"editcap -F libpcap active_device.pcapng active_device.pcap \"\n",
        "# 3. Then convert pcap files to .npt format using nprint command such as \"nprint -P active_device.pcap -W active_device_nprint/active_device_out.npt -4 -t -i\"\n",
        "# 4. Now the .npt file can ne loaded into pandas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "interpretml.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}